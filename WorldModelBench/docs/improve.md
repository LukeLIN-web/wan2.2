# WorldModelBench 改进计划：提高难度与区分度

## 现状诊断

从 9 个模型的排名数据可以看出核心问题：**分数区间太窄，天花板效应严重**。

| 问题 | 数据证据 |
|---|---|
| **总分区间压缩** | 9 个模型分布在 7.65–9.10，仅 1.45 分差（满分 10） |
| **物理维度饱和** | Newton 全场 0.99–1.00，Gravity 0.95–1.00，Fluid 0.98–1.00 |
| **Binary 评分太粗** | 物理 5 题 + 常识 2 题都是 Yes/No，大部分模型大部分题都是"No"（无违规），无法区分"轻微违规"和"完全正确" |
| **Instruction Following 双峰分布** | 57.7% 得 3 分，33.7% 得 1 分，只有 8% 得 2 分和 0.6% 得 0 分——中间档几乎没人 |
| **Judge 模型太弱** | 1.5B 参数的 VLM 很难检测细微物理违规，导致几乎全部回答 "No" |

**根本原因**：题目太简单（只问"有没有违规"）+ 评判太粗（Binary）+ Judge 太弱（1.5B）。

---

## 改进方向

### 1. 升级 Judge 模型（投入产出比最高）

**现状**：`vila-ewm-qwen2-1.5b`（1.5B）几乎检测不出物理违规，是区分度低的主因。

**方案**：
- 换用更强的开源 VLM：Qwen2.5-VL-72B、InternVL3-78B、或 LLaVA-OneVision-72B
- 也可用闭源 API：GPT-4o / Gemini 2.5 Pro 作为 upper bound 对比
- **关键**：不改题目，只换 Judge，对比分数分布是否改善——如果改善明显，说明瓶颈在 Judge 而非题目

**预期收益**：物理维度的 "No" 回答比例应显著下降，模型间区分度提升。

### 2. 物理评分从 Binary 改为 Likert 量表

**现状**：每个物理问题只问"有没有违规" → Yes/No → 0 或 1。

**方案**：改为 0–3 量表（与 Instruction Following 对齐）：

```
- 0: 严重违规，物理完全错误（如物体穿透、无重力漂浮）
- 1: 明显违规，但整体场景基本合理
- 2: 轻微违规，需仔细观察才能发现
- 3: 无违规，完全符合物理规律
```

Common Sense 同理改为 0–3。

**总分结构调整**：
| 维度 | 原满分 | 新满分 |
|---|---|---|
| Instruction Following | 3 | 3 |
| Physical Laws (5 题 × 3 分) | 5 | 15 |
| Common Sense (2 题 × 3 分) | 2 | 6 |
| **Total** | **10** | **24** |

归一化到 10 分制也行，但内部量表更细。

### 3. 增加物理评估的具体性

**现状**：物理问题太抽象泛泛，如 "Objects move without any external force"，1.5B 的 Judge 没法将这句话与视频中的具体现象对应。

**方案**：每个 domain 设计 **场景特化** 的物理检查问题：

| Domain | 特化物理问题示例 |
|---|---|
| Autonomous Vehicle | 刹车时车辆是否有惯性前倾？转弯时轮胎方向是否与运动方向一致？ |
| Robotics | 机械臂抓取物体时物体是否有合理重量感？放下物体时是否自然下落？ |
| Human Activities | 跳跃时重心轨迹是否抛物线？液体倒出时是否符合流体力学？ |
| Natural | 水波纹扩散方向是否正确？树叶飘落轨迹是否合理？ |
| Industrial | 机械齿轮联动方向是否正确？焊接火花飞溅是否符合物理？ |

这比通用问题更具体，Judge 更容易判断。

### 4. 增加时序因果推理维度（新维度）

**现状**：只评估"有没有"，不评估"顺序对不对"。

**方案**：新增 **Temporal Causality** 维度，测试因果链是否正确：

- "视频中事件的因果顺序是否合理？"（如：先踩刹车 → 再减速 → 再停车）
- "动作的前因后果是否连贯？"（如：杯子从桌上掉落 → 碎裂 → 碎片散开）
- 可设计 multi-step 场景：A 导致 B，B 导致 C，看模型能否完整生成因果链

**评分**：0–3 量表（完全错误 → 因果链完整正确）。

### 5. 提升 Instruction 的复杂度

**现状**：大部分 instruction 是简单的单动作（"The car stops"、"The robot picks up the object"）。

**方案**：分层设计 instruction 难度：

| 难度 | 示例 | 占比 |
|---|---|---|
| L1: 单动作 | "The car stops at the light." | 30% |
| L2: 条件动作 | "The car slows down when the pedestrian enters the crosswalk, then accelerates after they pass." | 30% |
| L3: 多步骤 | "The robot picks up the red block, places it on top of the blue block, then pushes both to the left." | 25% |
| L4: 反常识/罕见 | "The ball rolls uphill on the tilted surface due to the strong wind." | 15% |

L2–L4 会显著拉开模型差距：当前模型在简单单动作上都能拿高分，但多步骤/条件场景下会暴露差异。

### 6. 增加对抗样本（Adversarial Probing）

**目的**：专门针对已知弱点设计"陷阱题"。

**方案**：
- **物理陷阱**：场景中包含容易出错的物理交互（如碰撞、反弹、流体、布料）
- **计数陷阱**：instruction 中包含数量要求（"三个球依次落下"），测试模型是否能生成正确数量
- **空间关系陷阱**：要求特定空间关系（"A 在 B 的左上方"），测试空间一致性
- **时间陷阱**：要求特定时序（"先 A 再 B"），测试模型是否搞反顺序

### 7. 按难度分层报告（Difficulty Tiers）

**即使不改题目**，也可以通过事后分析提高区分度：

- 根据所有模型在每道题上的平均得分，将题目分为 Easy / Medium / Hard
- 分层报告分数：Easy 层大家都高分，Hard 层拉开差距
- 类似 MMLU 按 subject 难度分层报告

---

## 优先级排序

| 优先级 | 改进 | 理由 |
|---|---|---|
| **P0** | 升级 Judge 模型 | 不改任何题目，只换 Judge，就能显著提升区分度。最小改动、最大收益 |
| **P0** | Binary → Likert 量表 | 改 prompt + 解析逻辑即可，代码改动小 |
| **P1** | 物理问题具体化 | 需要 per-domain 设计问题，工作量中等 |
| **P1** | 按难度分层报告 | 纯后处理，不改数据和评测流程 |
| **P2** | Instruction 复杂度分层 | 需要重新设计 prompt + 采集新 first_frame 图片 |
| **P2** | 新增时序因果维度 | 需要新 prompt 模板 + 评测逻辑 |
| **P3** | 对抗样本 | 需要精心设计场景，工作量大 |

## 预期效果

- 分数区间从 ~1.5 分差扩大到 ~4–5 分差
- 消除物理维度的天花板效应（从 93%+ 降到 70–85% 的有效区分区间）
- 能区分"看起来还行"和"物理真正正确"的模型
